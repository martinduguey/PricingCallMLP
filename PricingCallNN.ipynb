{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pricing d'un call par perceptron multi-couches avec Numpy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1 . Introduction\n",
    "\n",
    "On s'intéresse à la mise en place intégrale d'un perceptron multi-couches pour établir le bon prix d'un call européen dans le monde de Black & Scholes. L'intérêt d'étudier un sous-jacent suivant une dynamique propre au modèle de Black & Scholes est de pouvoir créer une large base de données pour l'apprentissage, par exemple, et de pouvoir vérifier l'implémentation de notre modèle multi-couches. On se place, par la suite, dans l'espace de probabilité suivant $(\\Omega, \\mathcal{F}, \\mathbb{Q}^{*})$, où $\\mathbb{Q}^{*}$ désigne la probabilité risque-neutre.\n",
    "\n",
    "On considère donc dans la suite, un sous-jacent $\\{S_{t}\\}_{t \\geq 0}$ suivant la dynamique :\n",
    "\\begin{align}\n",
    "    dS_{t} = rS_{t}dt + \\sigma S_{t}dW_{t}\n",
    "\\end{align}\n",
    "où r est le rendement constant et positif d'un actif sans risque, $\\sigma$ la volatilité constante et positive du sous-jacent et $\\{W_{t}\\}_{t \\geq 0}$ un mouvement brownien standard.\n",
    "\n",
    "Par ailleurs, on pose $f$ la fonction $f : (t,x) \\mapsto f(t,x) = ln(x)$. En appliquant la formule d'Itô à $f(t,S_t)$ puis en intégrant sur l'intervalle $[0, t]$ on a, d'après (1) :\n",
    "\n",
    "\\begin{align*}\n",
    "    S_{t} = S_{0} e^{(r-\\frac{1}{2}\\sigma^{2})t + \\sigma W_{t}}, \\forall t \\geq 0.\n",
    "\\end{align*}\n",
    "On note alors que le processus actualisé $\\{e^{-rt}S_{t}\\}_{t\\geq 0}$ est une martingale sous la probabilité risque neutre $\\mathbb{Q}^{*}$.\n",
    "\n",
    "## 2 . Call, payoff et prix dans le monde de Black & Scholes\n",
    "\n",
    "### 2 . 1 . Rappels\n",
    "\n",
    "On se donne une maturité $T \\geq 0$, un strike $K > 0$ et on définit le payoff d'un call de la façon suivante :\n",
    "\n",
    "\\begin{align*}\n",
    "    (S_T-K)_{+} = \\max(S_T-K,0)\n",
    "\\end{align*}\n",
    "\n",
    "Par définition, en notant $\\mathcal{C}_{BS}$ le prix du call, on a :\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{C}_{BS} = e^{-rT} \\mathbb{E}_{\\mathbb{Q}^{*}} [ (S_T-K)_{+} ]\n",
    "\\end{align*}\n",
    "\n",
    "Lorsque l'actif $S$ a une dynamique suivant le modèle de Black-Scholes, on a une expression analytique de $\\mathcal{C}_{BS}$:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{C}_{BS}& = S_0F(\\alpha) - e^{-rT}KF(\\beta),&\\\\\n",
    "    \\text{avec, } \\alpha& = \\frac{1}{\\sigma \\sqrt{T}}(\\ln(\\frac{S_0}{K})+(r+\\frac{\\sigma^{2}}{2})T)),&\\\\\n",
    "    \\text{et, }\\beta& = \\frac{1}{\\sigma \\sqrt{T}}(\\ln(\\frac{S_0}{K})+(r-\\frac{\\sigma^{2}}{2})T)).\\\\\n",
    "\\end{align*}\n",
    "avec $F$ la fonction de répartition (CDF) d'une loi gaussienne centrée réduite.\n",
    "\n",
    "\n",
    "$\\underline{\\textit{démonstration :}}$\n",
    "\n",
    "On note que $(S_{T}-K)_{+} = (S_{T}-K)\\mathbb{1}_{\\{S_{T} \\geq K \\}}$ et que $\\{S_{T} \\geq K\\} = \\{ \\sigma W_{T} \\geq \\ln(\\frac{K}{S_0}) - (r - \\frac{\\sigma^{2}}{2})T\\}$ d'après $(1)$. On sait aussi que $W_{T} \\sim \\mathcal{N}(0,T)$ par définition, donc finalement :\n",
    "\\begin{align*}\n",
    "    W_{T} \\overset{\\mathcal{L}}{=} \\sqrt{T} G, \\quad G \\sim \\mathcal{N}(0,1) \n",
    "\\end{align*}\n",
    "\n",
    "On peut alors écrire $\\{S_{T} \\geq K \\} = \\{G \\geq \\frac{1}{\\sigma\\sqrt{T}}(\\ln(\\frac{K}{S_0}) - (r - \\frac{\\sigma^{2}}{2})T) \\}$. Pour ne pas alourdir l'écriture, on note pour la suite $\\gamma = \\frac{1}{\\sigma\\sqrt{T}}(\\ln(\\frac{K}{S_0}) - (r - \\frac{\\sigma^{2}}{2})T)$.\n",
    "Par ailleurs, par parité de la fonction de densité (PDF) de la loi gaussienne, il peut être nécessaire de rappeler que $G \\overset{\\mathcal{L}}{=} -G$.\n",
    "\n",
    "On a alors, en développant nos calculs :\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{C}_{BS}& = e^{-rT} \\mathbb{E}_{\\mathbb{Q}^{*}} [ (S_T-K) \\mathbb{1}_{\\{ G \\geq \\gamma \\}}],&\\\\\n",
    "    & = e^{-rT} \\mathbb{E}_{\\mathbb{Q}^{*}}[S_{T}\\mathbb{1}_{\\{ G \\geq \\gamma \\}}] - e^{-rT} K \\mathbb{E}_{\\mathbb{Q}^{*}}[\\mathbb{1}_{\\{ G \\geq \\gamma \\}}],&\\\\\n",
    "\\end{align*}\n",
    "\n",
    "On commence par développer le terme $e^{-rT} K \\mathbb{E}_{\\mathbb{Q}^{*}}[\\mathbb{1}_{\\{ G \\geq \\gamma \\}}]$:\n",
    "\\begin{align*}\n",
    "    e^{-rT} K \\mathbb{E}_{\\mathbb{Q}^{*}}[\\mathbb{1}_{\\{ G \\geq \\gamma \\}}] & = e^{-rT} K \\mathbb{Q}^{*}(G \\geq \\gamma),&\\\\\n",
    "    & = e^{-rT} K \\mathbb{Q}^{*}(-G \\geq \\gamma),&\\\\\n",
    "    & = e^{-rT} K F(\\beta),&\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Développons ensuite $e^{-rT} \\mathbb{E}_{\\mathbb{Q}^{*}}[S_{T}\\mathbb{1}_{\\{ G \\geq \\gamma \\}}]$:\n",
    "\\begin{align*}\n",
    "    e^{-rT} \\mathbb{E}_{\\mathbb{Q}^{*}}[S_{T}\\mathbb{1}_{\\{ G \\geq \\gamma \\}}] & = \\frac{e^{-rT}}{\\sqrt{2\\pi}}\\int_{\\gamma}^{+\\infty}S_{0}e^{(r-\\frac{1}{2}\\sigma^{2})T + \\sigma \\sqrt{T}x}e^{-\\frac{x^2}{2}}dx,&\\\\\n",
    "    & = \\frac{S_0}{\\sqrt{2\\pi}}\\int_{\\gamma}^{+\\infty}e^{-\\frac{1}{2}\\sigma^{2}T + \\sigma \\sqrt{T}x -\\frac{x^2}{2}}dx,&\\\\\n",
    "    & = \\frac{S_0}{\\sqrt{2\\pi}}\\int_{\\gamma}^{+\\infty}e^{-\\frac{1}{2}(x-\\sigma\\sqrt{T})}dx,&\\\\\n",
    "    & = \\int_{\\gamma - \\sigma\\sqrt{T}}^{+\\infty}e^{-\\frac{u^2}{2}}du, (u = x-\\sigma\\sqrt{T})&\\\\\n",
    "    & = S_0 \\mathbb{Q}^{*}(G \\geq \\gamma - \\sigma\\sqrt{T}),&\\\\\n",
    "    & = S_0 \\mathbb{Q}^{*}(-G \\geq -\\alpha), (-\\alpha = \\gamma - \\sigma\\sqrt{T})&\\\\\n",
    "    & = S_0 F(\\alpha).\n",
    "\\end{align*}\n",
    "\n",
    "On a finalement par sommmation:\n",
    "\\begin{align*}\n",
    "    \\mathcal{C}_{BS} = S_0F(\\alpha) - e^{-rT}KF(\\beta).\n",
    "\\end{align*}\n",
    "\n",
    "On peut alors contruire une fonction python qui calcule directement ce prix analytique en fonction des paramètres. On pourra par la suite utilisé cette fonction pour créer notre base de données d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openturns as ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactPriceCallBS(S0, r, sg, T, K):\n",
    "    \"\"\"\n",
    "        Fonction calculant le prix d'un call européen dans le monde de B&S en utilisant l'expression analytique.\n",
    "        -------\n",
    "        Parameters:\n",
    "    \n",
    "    S0 = Spot du sous-jacent.\n",
    "    r  = Rendement actif sans risque.\n",
    "    sg = Volatilité du sous-jacent.\n",
    "    T  = Maturité.\n",
    "    K  = Strike.\n",
    "\n",
    "        Returns:\n",
    "    \n",
    "    C  = Prix du call européen correspondant.\n",
    "    \"\"\"\n",
    "    alpha = (np.log(S0/K) + (r + sg**2/2)*T)/(sg*np.sqrt(T))\n",
    "    beta = (np.log(S0/K) + (r - sg**2/2)*T)/(sg*np.sqrt(T))\n",
    "    N = ot.Normal()\n",
    "\n",
    "    C = S0 * N.computeCDF(alpha) - np.exp(-r*T) * K * N.computeCDF(beta)  \n",
    "\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 . 2 . Données d'entraînement\n",
    "\n",
    "Monte-Carlo? LHS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 . Perceptron multi-couches\n",
    "\n",
    "Après avoir posé le contexte de notre étude, il s'agit ici d'expliciter le modèle neuronal permettant d'approcher $\\mathcal{C}_{BS}$. On désire obtenir un modèle $f_{\\omega}$, avec $\\omega$ une paramétrisation associée, tel que $f_{\\omega}(S_0,r,\\sigma,T,K)$ soit une bonne approximation de $\\mathcal{C}_{BS}(S_0,r,\\sigma,T,K)$. La particularité d'avoir un modèle perceptron et qu'il va falloir l'entraîner pour avoir une paramétrisation $\\hat{\\omega}$ optimale. Pour ce faire, on dispose de valeurs de $\\mathcal{C}_{BS}$ pour différentes combinaisons de $S_0,r,\\sigma,T$ et $K$. La notion de bonne approximation sera détaillée par la suite mais elle est tout de même liée à la notion de performance. La performance de notre modèle va dépendre des hyperparamètres de notre perceptron, en particulier le nombre de sous-couches et le nombre de neurones par couches. Mais aussi des fonctions d'activation utilisées, elles seront indispensables lors de l'étape d'optimisation sous-jacente au problème d'apprentissage du modèle, ou encore des données d'entraînement. Ce que l'on veut à tout prix éviter c'est que notre modèle garde en mémoire les données d'entraînement, données auxquelles on connaît le prix $\\mathcal{C}_{BS}$, à tel point qu'il ne peut plus s'en détacher.\n",
    "\n",
    "### 3.1 . Structure du modèle\n",
    "\n",
    "Dans les recherches de $\\textit{Bennell}$ & $\\textit{Sutcliffe}$ [1], un perceptron est utilisé pour estimer le prix d'un call européen. Entraîné à partir de données historiques, il est conçu pour ensuite être comparé au prix analytique d'un call d'après le modèle de Black & Scholes et ainsi mettre en lumière les limites de ce modèle. L'ambition est ici moindre dans le sens ou l'on souhaite construire un perceptron de manière à estimer le prix d'un call européen dans le monde de Black & Scholes. Il reste néanmoins intéressant de s'appuyer sur [1], pour avoir une idée de la structure du modèle. \n",
    "\n",
    "On fait le choix de construire dans un premier temps un perceptron à trois couches : une couche d'entrée, une couche intermédiaire et une couche de sortie. On pourra par la suite, mutliplier les couches intermédiaires si la performance de notre modèle n'est pas convaincante. Les travaux de $\\textit{Goodfellow et al}$ [3] ont permis de mettre en lumière le fait que plus le réseau neuronal dispose de couches intermédiaires plus il est performant. \n",
    "\n",
    "La couche d'entrée est composée de cinq noeuds, correspondant aux paramètres du prix du call sous notre hypothèse faite sur la dynamique de l'actif $\\{ S_{t}\\}_{t\\geq0}$, soit un noeud correspondant à $S_0$, à $r$, à $\\sigma$, à $T$ et à $K$. On pourra s'intérroger, par la suite, quant à la nécessité d'adimensionner nos données d'entrées comme cela a été fait dans [1], toujours dans l'optique de rendre notre modèle plus performant.\n",
    "\n",
    "Pour la couche intermédiaire, on fait le choix arbitraire de fixer sa contenance à dix noeuds. Comme pour le nombre de sous-couches, on pourra si nécessaire, ajouter plus de noeuds. On fait aussi le choix d'appliquer la même fonction d'activation pour tous les noeuds de la couche comme cela est courament fait dans la littérature. Pour la fonction d'activation, on choisit la fonction $\\textit{softplus}$ pour la continuité de sa dérivée, en tout point, et la positivité de son support d'activation.\n",
    "\n",
    "\\begin{align*}\n",
    "    f_{softplus} : x \\mapsto f_{softplus}(x) = \\ln(1 + e^{x})\n",
    "\\end{align*}\n",
    " \n",
    "La couche de sortie est composée d'un seul noeud, contenant notre estimation $\\hat{\\mathcal{C}_{BS}}$. On applique aussi la fonction $\\textit{softplus}$ à notre couche de sortie. Avant que notre modèle puisse estimer $\\mathcal{C}_{BS}$ par une valeur non-aberante, il faut l'entrainer. C'est ce qui est détaillé dans la partie suivante. On conclut cette partie en ajoutant que chaque couche est reliée, aux noeuds, par des poids. Ces poids constituent la paramétrisation $\\omega$ de notre modèle. Pour être complet sur la structure, il faudrait parler du taux d'apprentissage $\\eta$ du réseau dont on discutera plus tard de la valeur qui lui est associé. On rappelle que l'on cherche $\\hat{\\omega}$, intéressons-nous alors à la paramétrisation du modèle. \n",
    "\n",
    "### 3.2 . Apprentissage du modèle\n",
    "\n",
    "Notons $C$ la sortie de notre réseau non-entraîné. La phase d'apprentissage consiste à faire converger $C$ vers $\\mathcal{C}_{BS}$ en fixant un critère d'arrêt. Ce critère peut-être un nombre d'itérations maximal, communément appelé $epoch$ dans la littérature, ou une tolérance fixé sur l'erreur d'apprentissage.\n",
    "\n",
    "\\begin{align*}\n",
    "    C_{n} \\underset{n \\rightarrow N_{epoch}}{\\rightarrow} \\mathcal{C}_{BS}\n",
    "\\end{align*}\n",
    "\n",
    "Pour quantifier l'erreur d'apprentissage, appelée par la suite erreur de propagation, il nous faut définir prélablement la fonction que l'on veut minimiser, à chaque itération $n$, avant de mettre à jour nos poids. Dans [1], c'est l'erreur moyenne quadratique qui est minimisée. On introduit alors la fonction suivante :\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal{J}(\\omega) = \\frac{1}{N_{batch}} \\sum_{i = 1}^{N_{batch}} | C^{(i)} - \\mathcal{C}_{BS} |^{2}\n",
    "\\end{align*}\n",
    "où $N_{batch}$ est une partie des données dont on dispose pour entraîner notre perceptron. En particulier, il y autant de groupe de données de taille $N_{batch}$ qu'il y a d'iérations avant d'atteindre $N_{epoch}$. La minimisation de $\\mathcal{J}$ doit donc permettre de trouver $\\hat{\\omega}$. On note que raisonner par groupe d'échantillons d'entrée de taille $N_{batch}$ accelère la convergence de l'apprentissage de notre réseau, par rapport à un apprentissage pour chaque jeu de données fourni en entrée. Pour expliquer concrètement comment apprend notre réseau, on introduit la notion d'algorithme de rétropropagation.\n",
    "\n",
    "L'algorithme de rétropropagation permet de mettre à jour les paramètres $\\Omega$ une fois que le réseau en phase d'apprentissage a pu fournir des résultats à partir d'entrées. Cette mise à jour doit permettre de minimiser la fonction $\\mathcal{J}$ précédemment \n",
    "explicitée. Dans la suite, on note $e, 1, s$ les différentes couches de notre modèle et on introduit :\n",
    "\n",
    "$\\omega_{jk}^{l}$ : poids de la relation entre le k-ième neurone de la couche $l-1$ et le j-ième neurone de la couche l.\n",
    "\n",
    "$a_{j}^{l}$ : valeur du j-ième neurone de la couche l.\n",
    "\n",
    "$z_{j}^{l} = \\sum_{k = 1}^{N_{l-1}} \\omega_{jk}^{l}a_{k}^{l-1}$ avec $N_{l-1}$ le nombre de neurones sur la couche ${l-1}$.\n",
    "    \n",
    "On considère alors $\\Omega = \\{\\omega_e, \\omega_s\\}$ pour où donc $\\omega_e \\in \\mathcal{M}_{10,5}(\\mathbb{R})$, $\\omega_s \\in \\mathcal{M}_{1,10}(\\mathbb{R})$. Pour faciliter l'écriture vectorielle du problème de propagation, on fait le choix de voir l'erreur de propagation entre une couche $l-1$ et $l$ comme une conséquence d'une perturbation sur la somme pondérée $z_{j}^{l} \\forall j \\in \\mathbb{N}_{*}$ avec $j \\leq N_{l}$.\n",
    "On définit alors l'erreur $\\epsilon_{j}^{l} = \\frac{\\partial \\mathcal{J}}{\\partial z_{j}^{l}}$. Il vient donc par dérivation composée que :\n",
    "\\begin{align*}\n",
    "\t\\epsilon_{j}^{s} = \\frac{\\partial \\mathcal{J}}{\\partial a_{j}^{s}}\\frac{\\partial a_{j}^{s}}{\\partial z_{j}^{s}} =  \\frac{\\partial \\mathcal{J}}{\\partial a_{j}^{s}} f_{softplus}^{'}(z_{j}^{s}), \\quad j = 1 \\text{ pour la dernière couche}.\n",
    "\\end{align*}\n",
    "\n",
    "On note que comme on dispose que d'un noeud sur la dernière couche, $\\epsilon_{1}^{s}$ est un scalaire qu'on notera $\\epsilon^{s}$ dans la suite.\n",
    "\n",
    "Cependant on cherche à trouver les paramètres du modèle permettant de minimiser $\\mathcal{J}$, donc il faut pouvoir identifier $(\\nabla_{\\omega_{s}}\\mathcal{J})_{1k} = \\frac{\\partial \\mathcal{J}}{\\partial \\omega_{1k}^{s}}$. En fait, on a la relation de fermeture évidente : \n",
    "\\begin{align*}\n",
    "\t\\frac{\\partial \\mathcal{J}}{\\partial \\omega_{1k}^{s}} = \\frac{\\partial \\mathcal{J}}{\\partial z_{1}^{s}} \\frac{\\partial z_{1}^{s} }{\\partial \\omega_{1k}^{s}}  = \\epsilon^{s}a_{k}^{1}.\n",
    "\\end{align*}\n",
    "On note qu’on est autorisé à chercher une telle matrice $\\omega^{s}$ puisque $\\mathcal{J}$ est quadratique. La mise à jour des poids requiert donc un algorithme d'optimisation.\n",
    "\n",
    "Le choix d'optimisation étant à ce stade relativement libre, on se tourne vers l'algorithme d'Adam, détaillé dans les travaux de $\\textit{Kingma}$ & $\\textit{Ba}$ [2], pour sa facilité d'implémentation, son faible coût mémoire et sa performance.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\omega_{s} = \\omega_{s} - \\eta \\frac{\\hat{M}}{\\sqrt{\\hat{V}} + \\alpha}\n",
    "\\end{align*}\n",
    "où $\\hat{M}$ et $\\hat{V}$ sont respectivement un estimateur de la moyenne et un estimateur de la variance du gradient de la fonction coût à minimiser et $\\alpha$ est un coefficient arbitraire permettant\n",
    "de se prémunir des problèmes éventuels de la division. Dans le cas ci-dessus, $\\eta$ est en fait le pas lors de la descente de gradient, d'où son nom de taux d'apprentissage. Bien évidemment un grand pas permet de converger rapidement mais avec une paramétrisation potentiellement\n",
    "peu satisfaisante du modèle neuronal, tandis qu'un pas faible permet d'avoir une paramétrisation satisfaisante tout en ayant un temps d'apprentissage plus conséquent.\n",
    "\n",
    "L'algorithme d'Adam permet de mettre à jour les poids $\\omega_s$. Il faut donc aussi propager cette erreur pour mettre à jour les autres paramètres du modèle. Mais donc comme les neurones sont liés, d'une couche à l'autre par les poids et la fonctions d'activation \n",
    "il est possible de propager l'erreur obtenue. \n",
    "Autrement dit, on peut facilement obtenir $\\nabla_{\\omega_{e}}\\mathcal{J}$ à partir de $\\nabla_{\\omega_{s}}\\mathcal{J}$. En effet, soit $j \\in \\mathbb{N}$, $j \\leq 10$ fixé, puisqu'il y a dix noeuds sur la couche intermédiaire, on a alors :\n",
    "\\begin{align*}\n",
    "    \\epsilon_{j}^{1} &= \\frac{\\partial \\mathcal{J}}{\\partial z_{j}^{1}},&\\\\\n",
    "     &= \\frac{\\partial \\mathcal{J}}{\\partial a_{j}^{1}} f_{softplus}^{‘}(z_{j}^{1}),\\\\\n",
    "     &= \\frac{\\partial \\mathcal{J}}{\\partial a_{1}^{s}}  \\frac{\\partial a_{1}^{s}}{\\partial a_{j}^{1}} f_{softplus}^{‘}(z_{j}^{1}),&\\\\\n",
    "     &= \\omega_{1j}^{s} \\epsilon^{s} f_{softplus}^{‘}(z_{j}^{1}),&\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Ce qui donne sous forme vectorielle : \n",
    "\\begin{align*}\n",
    "\t\\epsilon^{1} = \\epsilon^{s} (\\omega^{s})^{T} \\star f_{softplus}^{‘}(z^{1})\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "### 3.3 . Implémentation du modèle avec Numpy\n",
    "\n",
    "On note qu'une approche objet serait plus adaptée pour ce projet ne serait-ce que pour pouvoir adapter plus facilement notre modèle, mais pour simplifier l'implémentation, on se restreint ici à une implémentation directe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Structure du perceptron\n",
    "\n",
    "# Hyperparamètres de structure et fonction(s) d'activation\n",
    "\n",
    "Ne = 5 #noeuds en entrée\n",
    "Ni = 10 #noeuds intermédiaires\n",
    "Ns = 1 #noeuds en sortie\n",
    "\n",
    "f_soft = lambda x : np.log(1+np.exp(x)) \n",
    "fp_soft = lambda x : 1/(1+np.exp(-x)) \n",
    "\n",
    "# Structure\n",
    "\n",
    "def MLP(Input, We, Ws, f_a1, f_a2):\n",
    "    \"\"\"\n",
    "        Fonction implémentant le modèle neuronale avec 3 couches.\n",
    "        --------\n",
    "        Parameters:\n",
    "    \n",
    "    Input : entrée du modèle.\n",
    "    We    : poids entre la couche d'entrée et la couche intermédiaire.\n",
    "    Ws    : poids entre la couche intermédiaire et la couche de sortie.\n",
    "    f_a1  : fonction d'activation pour la couche intermédiaire.\n",
    "    f_a2  : fonction d'activation pour la couche de sortie.\n",
    "\n",
    "        Returns:\n",
    "    \n",
    "    Output : sortie du modèle.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Passage couche d'entrée à couche intermédiaire\n",
    "    Inter = np.dot(We,Input)\n",
    "\n",
    "    # Activation couche intermédiaire\n",
    "    InterAct = f_a1(Inter)\n",
    "\n",
    "    # Passage couche intermédiaire à couche de sortie\n",
    "    Output = np.dot(Ws, InterAct)\n",
    "\n",
    "    # Activation couche de sortie\n",
    "    OutputAct = f_a2(Output)\n",
    "\n",
    "    return OutputAct, Output, InterAct, Inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Apprentissage du perceptron\n",
    "\n",
    "# Hyperparamètres d'apprentissage\n",
    "\n",
    "Nepochs = 1000  #nombre d'epochs\n",
    "eta = 0.001     #taux d'apprentissage\n",
    "tol = 10e-6     #tolérance MSE\n",
    "Nbatch = 32    \n",
    "\n",
    "# Apprentissage\n",
    "\n",
    "def PropagationMPL(InputNbatch, We, Ws, f_a1, f_a2):\n",
    "    \"\"\"\n",
    "        Fonction de propagation.\n",
    "        --------\n",
    "        Parameters:\n",
    "\n",
    "    InputNbatch : groupe d'entrées + 1 sortie de référence pour chacune des entrées (nécessaire pour MSE_Nbatch). Taille : (6,Nbatch)\n",
    "    We          : poids entre la couche d'entrée et la couche intermédiaire.\n",
    "    Ws          : poids entre la couche intermédiaire et la couche de sortie.\n",
    "    f_a1        : fonction d'activation pour la couche intermédiaire.\n",
    "    f_a2        : fonction d'activation pour la couche de sortie.\n",
    "\n",
    "        Returns:\n",
    "    \n",
    "    OutputNbatch : groupe de sorties. Taille : (1,Nbatch)\n",
    "    MSE_Nbatch   : Erreur quadratique sur l'ensemble des sorties.\n",
    "    \"\"\"\n",
    "    # Initialisation\n",
    "    Nbatch = np.shape(InputNbatch)[1] #entrées stockées par colonne\n",
    "\n",
    "    OutputNbatch = np.zeros(Nbatch)\n",
    "\n",
    "    # Séparation entrées/sorties de référence\n",
    "    OutputNbatchRef = InputNbatch[5,:]\n",
    "    InputNbatch = InputNbatch[0:5,:]\n",
    "\n",
    "    # Propagation\n",
    "    for i in range(Nbatch):\n",
    "        As, Zs, A1, Z1 = MLP(InputNbatch[:,i], We, Ws, f_a1, f_a2)\n",
    "        OutputNbatch[i] = As\n",
    "        \n",
    "    # Calcul MSE\n",
    "    MSE_Nbatch = np.sum(abs(OutputNbatch-OutputNbatchRef)**2)/Nbatch\n",
    "\n",
    "    ME_Nbatch = np.sum(abs(OutputNbatch-OutputNbatchRef))/Nbatch            \n",
    "\n",
    "    return OutputNbatch, MSE_Nbatch, ME_Nbatch, As, Zs, A1, Z1\n",
    "\n",
    "def AdamOpt(eta, gradJ, W, M, V, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8):\n",
    "    \"\"\"\n",
    "        Fonction effectuant 1 itération de l'algorithme d'Adam pour ajuster les poids selon la descente de gradient.\n",
    "        --------\n",
    "        Parameters:\n",
    "\n",
    "    eta     : taux d'apprentissage.\n",
    "    gradJ   : gradient fonction coût par rapport à W.\n",
    "    W       : poids de la couche.\n",
    "    M       : estimation de la moyenne.\n",
    "    V       : estimation de la variance.\n",
    "    beta1   : paramètre 1 de l'algorithme d'Adam.\n",
    "    beta2   : paramètre 2 de l'algorithme d'Adam.\n",
    "    epsilon : paramètre préventif pour la division.\n",
    "\n",
    "        Returns:\n",
    "    \n",
    "    Wmaj    : poids mis à jour.\n",
    "    Mmaj    : estimation de la moyenne mise à jour.\n",
    "    Vmaj    : estimation de la variance mise à jour.\n",
    "    \"\"\"\n",
    "    # Calculs préliminaires\n",
    "    Mmaj = beta1*M + (1-beta1)*gradJ\n",
    "    Vmaj = beta2*V + (1-beta2)*(gradJ**2)\n",
    "\n",
    "    Mmaj = Mmaj/(1-beta1)\n",
    "    Vmaj = Vmaj/(1-beta2)\n",
    "\n",
    "    # Mise à jour\n",
    "    Wmaj = W - eta * Mmaj/(np.sqrt(Vmaj) + epsilon)\n",
    "\n",
    "    return Wmaj, Mmaj, Vmaj\n",
    "\n",
    "def ComputeGradient(ME_Nbatch, Zs, A1, Z1, InputNbatch, Ws, fp_a1, fp_a2):\n",
    "    \"\"\"\n",
    "        Fonction permettant de calculer les gradients à partir des données de la dernière itération de la \n",
    "        propagation par paquet de taille Nbatch.\n",
    "        --------\n",
    "        Parameters:\n",
    "    \n",
    "    ME_Nbatch : Moyenne des écarts, en valeur absolue, aux données de référence du paquet de taille Nbatch.\n",
    "    Zs        : Valeur du neurone de sortie avant activation.\n",
    "    A1        : Valeurs finales des neurones de la couche intermédiaire.\n",
    "    Z1        : Valeurs avant activation des neurones de la couche intermédiaire.\n",
    "    InputNbatch : Valeurs des entrées à la dernière itération de propagation des données.\n",
    "    Ws        : Poids entre le neurone de sortie et la couche intermédiaire.\n",
    "    fp_a1     : Dérivée de la fonction d'activation pour la couche intermédiaire.\n",
    "    fp_a2     : Dérivée de la fonction d'activation pour la couche (1 neurone) de sortie.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "    gradJe    : Matrice gradient de J par rapport à chacun des poids We. Taille : (10, 5)\n",
    "    gradJs    : Vecteur gradient de J par rapport à chacun des poids Ws. Taille : (1, 10)\n",
    "    \"\"\"\n",
    "    # Compute gradJs\n",
    "    epsilon_s = 2*ME_Nbatch * fp_a2(Zs) #scalaire puisque Zs est scalaire\n",
    "    gradJs = epsilon_s*A1\n",
    "\n",
    "    # Commpute gradJe\n",
    "    epsilon_1 = epsilon_s* Ws * fp_a1(Z1)\n",
    "    gradJe = np.outer(epsilon_1, InputNbatch)\n",
    "\n",
    "    return gradJe, gradJs\n",
    "\n",
    "def RetropropagationMLP(eta, gradJe, gradJs, We, Me, Ve, Ws, Ms, Vs):\n",
    "    \"\"\"\n",
    "        Fonction permettant de rétropropager l'erreur dans le réseau.\n",
    "        --------\n",
    "        Parameters:\n",
    "    \n",
    "    eta     : taux d'apprentissage.\n",
    "    gradJe  : gradient fonction coût par rapport à We.\n",
    "    gradJs  : gradient fonction coût par rapport à Ws.\n",
    "    We      : poids couche d'entrée.\n",
    "    Me      : estimation de la moyenne.\n",
    "    Ve      : estimation de la variance.\n",
    "    Ws      : poids couche d'entrée.\n",
    "    Ms      : estimation de la moyenne.\n",
    "    Vs      : estimation de la variance.\n",
    "\n",
    "        Returns:\n",
    "    \n",
    "    We_maj    : poids We mis à jour.\n",
    "    Me_maj    : estimation de la moyenne mise à jour.\n",
    "    Ve_maj    : estimation de la variance mise à jour.\n",
    "    Ws_maj    : poids Ws mis à jour.\n",
    "    Ms_maj    : estimation de la moyenne mise à jour.\n",
    "    Vs_maj    : estimation de la variance mise à jour.\n",
    "    \"\"\"\n",
    "    # We\n",
    "    We_maj, Me_maj, Ve_maj = AdamOpt(eta, gradJe, We, Me, Ve, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8)\n",
    "\n",
    "    # Ws\n",
    "    Ws_maj, Ms_maj, Vs_maj = AdamOpt(eta, gradJs, Ws, Ms, Vs, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8)\n",
    "\n",
    "    return We_maj, Me_maj, Ve_maj, Ws_maj, Ms_maj, Vs_maj\n",
    "\n",
    "def Apprentissage(InputApp, Nepochs, Nbatch, f_a1, f_a2, fp_a1, fp_a2, eta, tol):\n",
    "    \"\"\"\n",
    "        Fonction réalisant l'apprentissage du modèle.\n",
    "        --------\n",
    "        Parameters:\n",
    "\n",
    "    InputApp : données d'apprentissage. Taille : (6,Nepochs*Nbatch) à minima voir plus si cross-validation.\n",
    "    Nepochs  : nombre d'itérations pour l'apprentissage. \n",
    "    Nbatch   : nombre d'entrées pour la mise à jour/rétropropagation.\n",
    "    eta      : taux d'apprentissage.\n",
    "    f_a1     : fonction d'activation pour la couche intermédiaire.\n",
    "    f_a2     : fonction d'activation pour la couche de sortie.\n",
    "    fp_a1    : dérivée de la fonction d'activation pour la couche intermédiaire.\n",
    "    fp_a2    : dérivée de la fonction d'activation pour la couche (1 neurone) de sortie.\n",
    "    tol      : tolérance sur la valeur de J après propagation.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "    WeOpt    : poids optimaux pour la couche We.\n",
    "    WsOpt    : poids optimaux pour la couche Ws.\n",
    "    \"\"\"\n",
    "    # for i in range(Nepochs)\n",
    "    #   change les entrées de la propagation\n",
    "    #   Propagation\n",
    "    #   Gradient de J\n",
    "    #   Si MSE_Nbatch > tol :\n",
    "    #     Retropropagation -> récuperer les W, M, V pour chaque couche\n",
    "\n",
    "    # Initialisation des poids \n",
    "    Ws = np.zeros((Ns,Ni))\n",
    "    We = np.zeros((Ni,Ne))\n",
    "\n",
    "    # Initialisation des moments\n",
    "    Me = np.zeros(np.shape(We))\n",
    "    Ve = np.zeros(np.shape(We))\n",
    "\n",
    "    Ms = np.zeros(np.shape(Ws))\n",
    "    Vs = np.zeros(np.shape(Ws))\n",
    "    \n",
    "    # Apprentissage\n",
    "    for i in range(Nepochs):\n",
    "        print(str(i)+' epochs')\n",
    "        InputNbatch = InputApp[i*Nbatch,(i+1)*Nbatch]\n",
    "        OutputNbatch, MSE_Nbatch, ME_Nbatch, As, Zs, A1, Z1 = PropagationMPL(InputNbatch, We, Ws, f_a1, f_a2)\n",
    "\n",
    "        if(MSE_Nbatch > tol):\n",
    "            gradJe, gradJs =  ComputeGradient(ME_Nbatch, Zs, A1, Z1, InputNbatch[:,Nbatch], fp_a1, fp_a2)\n",
    "            We, Me, Ve, Ws, Ms, Vs = RetropropagationMLP(eta, gradJe, gradJs, We, Me, Ve, Ws, Ms, Vs)\n",
    "\n",
    "    WeOpt = We\n",
    "    WsOpt = Ws\n",
    "\n",
    "    return WeOpt, WsOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Référence\n",
    "\n",
    "[1] - Bennell, Julia & Sutcliffe Charles, $\\textit{Black-Scholes versus artificial neural networks in pricing FTSE 100 options}$, online, Wiley InterScience, 2004.\n",
    "\n",
    "[2] - Kingma, Diederik P. & Ba, Jimmy Lei, $\\textit{Adam: a method for stochastic optimization}$, conference paper, ICLR, 2015.\n",
    "\n",
    "[3] - Goodfellow, Ian & Bengio, Yoshua & Courville, Aaron, $\\textit{Deep learning}$, published, MIT Press, 2016.\n",
    "\n",
    "[4] - Nielsen, Michael, $\\textit{Neural Networks and Deep learning}$, online, Determination Press, 2015.\n",
    "\n",
    "[5] - Nsenge, Mpia Héritier & Inipaivudu, Baelani Nephtali, $\\textit{L’Algorithme de rétro-propagation de gradient dans le perceptron multicouche: Bases et étude de cas}$, online, Innovative Space of Scientific Research Journals, 2021."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
